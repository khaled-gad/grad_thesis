\contentsline {section}{Abstract}{5}{section*.4}%
\contentsline {section}{Acknowledgment}{6}{section*.5}%
\contentsline {section}{List of Abbreviations}{7}{section*.6}%
\contentsline {section}{\numberline {1}Introduction}{8}{section.1}%
\contentsline {subsection}{\numberline {1.1}Motivation}{8}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Limitations of Current Solutions}{9}{subsection.1.2}%
\contentsline {subsection}{\numberline {1.3}The RISC-V Vector Extension as a Solution}{9}{subsection.1.3}%
\contentsline {subsection}{\numberline {1.4}Problem Statement}{10}{subsection.1.4}%
\contentsline {subsection}{\numberline {1.5}Project Objectives}{10}{subsection.1.5}%
\contentsline {subsection}{\numberline {1.6}Project Contributions}{11}{subsection.1.6}%
\contentsline {subsection}{\numberline {1.7}Thesis Organization}{12}{subsection.1.7}%
\contentsline {section}{\numberline {2}Background \& Related Work}{13}{section.2}%
\contentsline {subsection}{\numberline {2.1}RISC-V Architecture Overview}{13}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}RISC-V Extensions for Machine Learning}{14}{subsection.2.2}%
\contentsline {subsubsection}{\numberline {2.2.1}Standard Extensions}{14}{subsubsection.2.2.1}%
\contentsline {subsection}{\numberline {2.3}The RISC-V Vector Extension}{14}{subsection.2.3}%
\contentsline {subsubsection}{\numberline {2.3.1}Architectural Principles}{14}{subsubsection.2.3.1}%
\contentsline {subsubsection}{\numberline {2.3.2}Programming with RISC-V Vector Intrinsics}{15}{subsubsection.2.3.2}%
\contentsline {subsection}{\numberline {2.4}Related Work: The RISC-V landscape for Vector Computing}{16}{subsection.2.4}%
\contentsline {paragraph}{System-Level Infrastructure for RISC-V Vector Design}{16}{section*.7}%
\contentsline {paragraph}{Compiler, Application, and System-Level Performance Evaluation}{17}{section*.12}%
\contentsline {section}{\numberline {3}Methodology: Architecture \& Implementations}{19}{section.3}%
\contentsline {subsection}{\numberline {3.1}Deep Learning Kernel Selection and Justification}{19}{subsection.3.1}%
\contentsline {subsubsection}{\numberline {3.1.1}Selection Criteria Categories}{19}{subsubsection.3.1.1}%
\contentsline {subsubsection}{\numberline {3.1.2}RVV Vectorization Benefits by Category}{20}{subsubsection.3.1.2}%
\contentsline {subsection}{\numberline {3.2}Development Toolchain}{21}{subsection.3.2}%
\contentsline {subsubsection}{\numberline {3.2.1}RISC-V GNU Toolchain}{21}{subsubsection.3.2.1}%
\contentsline {paragraph}{Toolchain Components}{21}{section*.18}%
\contentsline {subsubsection}{\numberline {3.2.2}QEMU Emulator}{22}{subsubsection.3.2.2}%
\contentsline {paragraph}{Rationale for Using QEMU}{22}{section*.19}%
\contentsline {paragraph}{QEMU User-Mode Emulation}{22}{section*.20}%
\contentsline {paragraph}{QEMU System-Mode Emulation}{22}{section*.21}%
\contentsline {paragraph}{Role in the Verification Workflow}{23}{section*.22}%
\contentsline {subsubsection}{\numberline {3.2.3}ONNX: Open Neural Network Exchange}{23}{subsubsection.3.2.3}%
\contentsline {paragraph}{Components of ONNX and Their Role in the Project}{23}{section*.23}%
\contentsline {subparagraph}{ONNX Model Components}{23}{section*.24}%
\contentsline {subparagraph}{Role of ONNX in the Project}{24}{section*.25}%
\contentsline {subsection}{\numberline {3.3}RISC-V Vectorization Kernels Design}{24}{subsection.3.3}%
\contentsline {subsubsection}{\numberline {3.3.1}Pattern 1: Compute-Bound FMA Operations}{24}{subsubsection.3.3.1}%
\contentsline {paragraph}{Matrix Multiplication (GEMM)}{25}{section*.26}%
\contentsline {subparagraph}{Kernel Description}{25}{section*.27}%
\contentsline {subparagraph}{Scalar Implementation}{25}{section*.28}%
\contentsline {subparagraph}{Vectorization Strategy}{25}{section*.29}%
\contentsline {subparagraph}{Implementation}{26}{section*.30}%
\contentsline {paragraph}{Dense Layer (Fully Connected)}{26}{section*.31}%
\contentsline {subparagraph}{Kernel Description}{26}{section*.32}%
\contentsline {subparagraph}{Scalar Implementation}{27}{section*.33}%
\contentsline {subparagraph}{Vectorization Strategy}{27}{section*.34}%
\contentsline {subparagraph}{Implementation}{27}{section*.35}%
\contentsline {subsubsection}{\numberline {3.3.2}Pattern 2: Sliding Window Kernels}{28}{subsubsection.3.3.2}%
\contentsline {paragraph}{2D Convolution}{28}{section*.36}%
\contentsline {subparagraph}{Kernel Description}{28}{section*.37}%
\contentsline {subparagraph}{Scalar Implementation}{29}{section*.38}%
\contentsline {subparagraph}{General Vectorization}{29}{section*.39}%
\contentsline {subparagraph}{Implementation}{30}{section*.40}%
\contentsline {subparagraph}{Convolution as Matrix Multiplication (Im2Col)}{31}{section*.41}%
\contentsline {subparagraph}{Specialized 3x3 Vectorization}{32}{section*.42}%
\contentsline {paragraph}{Max Pooling}{33}{section*.43}%
\contentsline {subparagraph}{Kernel Description}{33}{section*.44}%
\contentsline {subparagraph}{Scalar Implementation}{33}{section*.45}%
\contentsline {subparagraph}{Vectorization Strategy}{34}{section*.46}%
\contentsline {subparagraph}{Implementation}{34}{section*.47}%
\contentsline {subsubsection}{\numberline {3.3.3}Pattern 3: Pointwise/Elementwise Kernels}{35}{subsubsection.3.3.3}%
\contentsline {paragraph}{ReLU and Leaky ReLU Activation Functions}{36}{section*.48}%
\contentsline {paragraph}{Bias Add and Tensor Add Operations}{37}{section*.49}%
\contentsline {subsubsection}{\numberline {3.3.4}Pattern 4: Tensor Indexing and Data Movement}{38}{subsubsection.3.3.4}%
\contentsline {paragraph}{Gather and Gather Elements}{39}{section*.50}%
\contentsline {subparagraph}{Kernel Description}{39}{section*.51}%
\contentsline {subparagraph}{Scalar Implementation}{39}{section*.52}%
\contentsline {subparagraph}{Vectorization Strategy}{39}{section*.53}%
\contentsline {subparagraph}{Implementation}{39}{section*.54}%
\contentsline {paragraph}{Scatter Elements}{40}{section*.55}%
\contentsline {subparagraph}{Kernel Description}{40}{section*.56}%
\contentsline {subparagraph}{Scalar Implementation}{40}{section*.57}%
\contentsline {subparagraph}{Vectorization Strategy}{40}{section*.58}%
\contentsline {subparagraph}{Implementation}{40}{section*.59}%
\contentsline {subsubsection}{\numberline {3.3.5}Pattern 5: Batch Normalization}{41}{subsubsection.3.3.5}%
\contentsline {paragraph}{Batch Normalization}{41}{section*.60}%
\contentsline {subparagraph}{Kernel Description}{41}{section*.61}%
\contentsline {subparagraph}{Scalar Implementation}{41}{section*.62}%
\contentsline {subparagraph}{Vectorization Strategy}{42}{section*.63}%
\contentsline {subparagraph}{Implementation}{42}{section*.64}%
\contentsline {subsubsection}{\numberline {3.3.6}Pattern 6: Post-Processing Kernels - Non-Maximum Suppression}{43}{subsubsection.3.3.6}%
\contentsline {paragraph}{Scalar NMS Algorithm}{43}{section*.65}%
\contentsline {paragraph}{Vectorized NMS Implementation}{44}{section*.66}%
\contentsline {paragraph}{Vectorized IoU Computation}{45}{section*.67}%
\contentsline {subsection}{\numberline {3.4}Functional Verification Results and Discussion}{46}{subsection.3.4}%
\contentsline {subsubsection}{\numberline {3.4.1}Test Setup and Verification Flow}{46}{subsubsection.3.4.1}%
\contentsline {subsubsection}{\numberline {3.4.2}Verification Architecture}{46}{subsubsection.3.4.2}%
\contentsline {subsubsection}{\numberline {3.4.3}Verification Metrics}{46}{subsubsection.3.4.3}%
\contentsline {paragraph}{Signal-to-Noise Ratio (SNR)}{47}{section*.68}%
\contentsline {paragraph}{Maximum Absolute Error}{47}{section*.69}%
\contentsline {subsubsection}{\numberline {3.4.4}Verification Thresholds}{48}{subsubsection.3.4.4}%
\contentsline {subsubsection}{\numberline {3.4.5}Discrete Functions Correctness Verification Results}{48}{subsubsection.3.4.5}%
\contentsline {paragraph}{Perfect Accuracy (Tier 1):}{51}{section*.70}%
\contentsline {paragraph}{Excellent Accuracy (Tier 2):}{52}{section*.71}%
\contentsline {paragraph}{Very High Accuracy (Tier 3):}{52}{section*.72}%
\contentsline {subsubsection}{\numberline {3.4.6}Models}{52}{subsubsection.3.4.6}%
\contentsline {paragraph}{Model Selection Rationale:}{52}{section*.73}%
\contentsline {paragraph}{LeNet-5 Architecture and Implementation:}{53}{section*.74}%
\contentsline {paragraph}{Tiny-YOLOv2 Architecture and Implementation:}{54}{section*.75}%
\contentsline {paragraph}{Verification Methodology and Results:}{56}{section*.76}%
\contentsline {section}{\numberline {4}Methodology: Performance Validation}{58}{section.4}%
\contentsline {subsection}{\numberline {4.1}Hardware (RTL Cores)}{58}{subsection.4.1}%
\contentsline {subsubsection}{\numberline {4.1.1}Role of RTL Cores in Architectural Research}{58}{subsubsection.4.1.1}%
\contentsline {subsubsection}{\numberline {4.1.2}Importance of Cycle-Accurate Simulation}{58}{subsubsection.4.1.2}%
\contentsline {subsubsection}{\numberline {4.1.3}Evolution of Core Selection: From Vicuna to Ara}{58}{subsubsection.4.1.3}%
\contentsline {subsection}{\numberline {4.2}Vicuna RISC-V Vector Coprocessor}{59}{subsection.4.2}%
\contentsline {subsubsection}{\numberline {4.2.1}Overview and Design Motivation}{59}{subsubsection.4.2.1}%
\contentsline {subsubsection}{\numberline {4.2.2}Architectural Organization}{59}{subsubsection.4.2.2}%
\contentsline {subsubsection}{\numberline {4.2.3}RVV Implementation}{60}{subsubsection.4.2.3}%
\contentsline {subsubsection}{\numberline {4.2.4}Execution Model}{60}{subsubsection.4.2.4}%
\contentsline {subsubsection}{\numberline {4.2.5}Memory Subsystem}{61}{subsubsection.4.2.5}%
\contentsline {subsubsection}{\numberline {4.2.6}RTL Implementation}{61}{subsubsection.4.2.6}%
\contentsline {subsubsection}{\numberline {4.2.7}Benchmarking Suitability}{61}{subsubsection.4.2.7}%
\contentsline {subsection}{\numberline {4.3}Ara Vector Processor}{62}{subsection.4.3}%
\contentsline {subsubsection}{\numberline {4.3.1}Overview and Design Motivation}{62}{subsubsection.4.3.1}%
\contentsline {subsubsection}{\numberline {4.3.2}Architectural Organization}{62}{subsubsection.4.3.2}%
\contentsline {subsubsection}{\numberline {4.3.3}Vector Execution Model}{63}{subsubsection.4.3.3}%
\contentsline {subsubsection}{\numberline {4.3.4}Memory Subsystem and Coherence}{63}{subsubsection.4.3.4}%
\contentsline {subsubsection}{\numberline {4.3.5}RTL Implementation and Scalability}{64}{subsubsection.4.3.5}%
\contentsline {subsubsection}{\numberline {4.3.6}Benchmarking Suitability}{64}{subsubsection.4.3.6}%
\contentsline {subsection}{\numberline {4.4}Comparative Analysis and Core Selection Rationale}{64}{subsection.4.4}%
\contentsline {subsubsection}{\numberline {4.4.1}Architectural Trade-offs}{64}{subsubsection.4.4.1}%
\contentsline {subsubsection}{\numberline {4.4.2}Rationale for Benchmarking on Ara}{64}{subsubsection.4.4.2}%
\contentsline {subsubsection}{\numberline {4.4.3}Summary of Methodology Pivot}{65}{subsubsection.4.4.3}%
\contentsline {subsection}{\numberline {4.5}Validation Strategy}{65}{subsection.4.5}%
\contentsline {subsubsection}{\numberline {4.5.1}Testbench Structure and Workflow}{65}{subsubsection.4.5.1}%
\contentsline {subsubsection}{\numberline {4.5.2}Cycle-Accurate Measurement Logic}{66}{subsubsection.4.5.2}%
\contentsline {subsubsection}{\numberline {4.5.3}Hardware Configuration and Leaky ReLU Case Study}{67}{subsubsection.4.5.3}%
\contentsline {subsection}{\numberline {4.6}Validation Results}{68}{subsection.4.6}%
\contentsline {subsubsection}{\numberline {4.6.1}Performance Overview}{69}{subsubsection.4.6.1}%
\contentsline {subsubsection}{\numberline {4.6.2}Compute-Bound FMA Operations}{69}{subsubsection.4.6.2}%
\contentsline {subsubsection}{\numberline {4.6.3}Sliding Window \& Filters}{70}{subsubsection.4.6.3}%
\contentsline {subsubsection}{\numberline {4.6.4}Pointwise \& Elementwise Operations}{71}{subsubsection.4.6.4}%
\contentsline {subsubsection}{\numberline {4.6.5}Results Discussion}{72}{subsubsection.4.6.5}%
\contentsline {paragraph}{Compute-Bound Operations (MatMul \& Dense Layers)}{72}{section*.77}%
\contentsline {paragraph}{Sliding Window Operations (Convolution \& Max Pooling)}{73}{section*.78}%
\contentsline {paragraph}{Pointwise and Elementwise Operations (Activation \& Additive Kernels)}{73}{section*.79}%
\contentsline {paragraph}{Overall Analysis}{74}{section*.80}%
\contentsline {section}{\numberline {5}Open Source Library Architecture}{75}{section.5}%
\contentsline {subsection}{\numberline {5.1}Repository Structure}{75}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Explanation of Repository Contents}{75}{subsection.5.2}%
\contentsline {subsection}{\numberline {5.3}Wrappers Overview}{76}{subsection.5.3}%
\contentsline {subsubsection}{\numberline {5.3.1}Intrinsic Wrappers}{76}{subsubsection.5.3.1}%
\contentsline {subsubsection}{\numberline {5.3.2}Python Wrappers}{76}{subsubsection.5.3.2}%
\contentsline {subsection}{\numberline {5.4}Results Verification}{77}{subsection.5.4}%
\contentsline {subsubsection}{\numberline {5.4.1}Correctness Testing}{77}{subsubsection.5.4.1}%
\contentsline {subsubsection}{\numberline {5.4.2}Automated Testing}{77}{subsubsection.5.4.2}%
\contentsline {subsection}{\numberline {5.5}Performance Results}{77}{subsection.5.5}%
\contentsline {subsubsection}{\numberline {5.5.1}Benchmarking Framework}{77}{subsubsection.5.5.1}%
\contentsline {subsubsection}{\numberline {5.5.2}Performance Metrics}{78}{subsubsection.5.5.2}%
\contentsline {subsection}{\numberline {5.6}Wrapper Interfaces}{78}{subsection.5.6}%
\contentsline {subsubsection}{\numberline {5.6.1}Example Function Signature}{79}{subsubsection.5.6.1}%
\contentsline {section}{\numberline {6}Conclusion and Future Work}{80}{section.6}%
\contentsline {subsection}{\numberline {6.1}Conclusion}{80}{subsection.6.1}%
\contentsline {subsection}{\numberline {6.2}Future Work}{80}{subsection.6.2}%
\contentsline {subsubsection}{\numberline {6.2.1}Extension to Additional Workload Domains}{80}{subsubsection.6.2.1}%
\contentsline {subsubsection}{\numberline {6.2.2}Deployment on Physical RISC-V Hardware}{81}{subsubsection.6.2.2}%
\contentsline {subsubsection}{\numberline {6.2.3}Enhancement of the Python Interface and Abstraction Layer}{81}{subsubsection.6.2.3}%
\contentsline {subsubsection}{\numberline {6.2.4}Kernel Optimization and Algorithmic Improvements}{81}{subsubsection.6.2.4}%
\contentsline {subsubsection}{\numberline {6.2.5}Expanded Neural Network Model Support}{81}{subsubsection.6.2.5}%
\contentsline {section}{\numberline {7}Code Listings}{85}{section.7}%
