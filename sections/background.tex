\section{Background \& Related Work}

\subsection{RISC-V Architecture Overview}

RISC-V (pronounced ``risk-five'') is an open-source instruction set architecture (ISA) that has revolutionized processor design by providing a free, extensible alternative to proprietary architectures. Developed at the University of California, Berkeley, beginning in 2010, RISC-V was created to address fundamental limitations in the processor industry, particularly the dominance of proprietary ISAs that created barriers to innovation and increased costs for processor development.

The development of RISC-V was motivated by several critical issues in the computing industry that had become increasingly problematic for AI and DSP applications. Traditional proprietary ISAs, such as x86 and ARM, require expensive licensing agreements that can be prohibitive for companies developing specialized processors for AI and DSP workloads. These licensing costs are particularly burdensome for startups and research institutions that want to experiment with novel architectural approaches.

RISC-V addresses these challenges through several fundamental design principles that make it particularly well-suited for AI and DSP applications:

\textbf{Open Source Philosophy:} RISC-V specifications are freely available under Creative Commons licenses, and anyone can implement, modify, or extend RISC-V processors without paying royalties or obtaining permission. This openness eliminates one of the major barriers to innovation in processor design and enables a diverse ecosystem of implementations tailored for specific applications.

\textbf{Modular Architecture:} RISC-V follows a modular design philosophy where a minimal base integer instruction set is supplemented by optional standard extensions. This modularity is particularly valuable for AI and DSP processors, which can include only the extensions needed for their specific applications, reducing implementation complexity and cost.


\textbf{Scalability Across Application Domains:} RISC-V supports multiple data widths (32-bit, 64-bit, and 128-bit) and can scale from microcontrollers to high-performance processors. This scalability is crucial for AI and DSP applications, which span a wide range of computing environments from embedded edge devices to high-performance computing clusters.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/growth.png}
    \caption{RISC-V ecosystem growth. Source: RISC-V International}
    \label{ RISC-V ecosystem growth. Source: RISC-V International}
\end{figure}    


\subsection{RISC-V Extensions for Machine Learning}

The extensible nature of RISC-V is fundamental to its success in AI and DSP applications, allowing specialized functionality to be added to the base instruction set through a well-defined extension mechanism. This extensibility enables processors to be tailored for specific application domains while maintaining compatibility with the broader RISC-V ecosystem.

\subsubsection{Standard Extensions}

\textbf{M Extension (Integer Multiplication and Division):} The M extension adds integer multiplication, division, and remainder operations that are fundamental for many AI and DSP algorithms. In AI applications, integer multiplication is crucial for quantized neural networks that use integer arithmetic instead of floating-point operations to reduce power consumption and increase performance.

\textbf{F Extension (Single-Precision Floating-Point):} The F extension provides IEEE 754 single-precision (32-bit) floating-point arithmetic, which is the most commonly used precision for AI training and many DSP applications. The extension includes fused multiply-add (FMA) instructions that are particularly important for AI and DSP workloads, as convolution operations in neural networks consist primarily of multiply-accumulate patterns that can be efficiently implemented using FMA instructions.

\textbf{D Extension (Double-Precision Floating-Point):} The D extension adds IEEE 754 double-precision (64-bit) floating-point arithmetic, which is important for AI training applications that require higher numerical precision and certain DSP applications that need extended dynamic range.

\textbf{V Extension (Vector Operations):} The V extension is the most significant addition to RISC-V for AI and DSP applications, providing comprehensive support for data-parallel vector operations. This extension represents a fundamental advancement in vector processing architecture and is the primary focus of this work.

\subsection{The RISC-V Vector Extension}

The RISC-V Vector (RVV) Extension stands out as one of the most consequential developments for modern computing workloads. Unlike traditional Single Instruction, Multiple Data (SIMD) architectures that operate on fixed-size registers, RVV was designed with a philosophy of flexibility, scalability, and efficiency achieved through novel architectural concepts.

\subsubsection{Architectural Principles}

\textbf{Vector Registers and Configuration:} The V extension introduces 32 vector registers (\texttt{v0}--\texttt{v31}). The core architectural parameter is VLEN (Vector Length), which specifies the length of these registers in bits. VLEN is an implementation-defined choice, not fixed by the specification, and can range from small values (e.g., 128 bits) for embedded systems to very large values (e.g., 4096 bits or more) for supercomputers. Another key parameter is ELEN (Element Length), which is the maximum size of a single data element that can be processed.

\textbf{Vector Control and Status Registers (CSRs):} The power and flexibility of the V extension are managed through key Control and Status Registers:

\begin{itemize}
    \item \texttt{vtype}: Configures the vector unit for subsequent operations by setting the selected element width (\texttt{vsew}), vector length multiplier (\texttt{vlmul}) for register grouping, and behavior controls for tail and masked-out elements (\texttt{vta}/\texttt{vma}).
    \item \texttt{vl}: Set by the programmer to specify the number of elements to process in upcoming vector instructions, ranging from 0 to a hardware-dependent maximum.
    \item \texttt{vlenb}: A read-only register that reports the hardware's vector register length (VLEN) in bytes.
\end{itemize}

\textbf{Vector-Length Agnostic (VLA) Execution:} The combination of the \texttt{vsetvli} instruction and the \texttt{vl} register enables RVV's most powerful feature: Vector-Length Agnosticism. Unlike fixed-length SIMD (e.g., Intel's AVX or ARM's NEON), where code is written for a specific vector width, VLA code is portable across any hardware implementation, regardless of its VLEN.

The typical execution flow follows a ``strip-mining'' pattern:
\begin{enumerate}
    \item A programmer has a large array of N elements to process
    \item The code enters a loop and calls \texttt{vsetvli}, passing the remaining number of elements
    \item The hardware automatically sets \texttt{vl} to the minimum of the requested number and the maximum it can physically handle (VMAX), configuring \texttt{vtype} appropriately
    \item Subsequent vector instructions operate on \texttt{vl} elements
    \item The loop continues, processing chunks of data until all N elements are complete
\end{enumerate}

This approach means a single compiled binary can run with optimal efficiency on both a low-power microcontroller with VLEN=128 and a high-performance compute node with VLEN=4096, without requiring recompilation or code modification.

\textbf{Rich and Orthogonal Instruction Set:} The V extension provides a comprehensive set of instructions orthogonal to data types, allowing the same opcodes to work on integers and floats of different widths as configured by \texttt{vtype}. Key instruction categories include:

\begin{itemize}
    \item \textbf{Vector Arithmetic:} Integer, fixed-point, and floating-point operations
    \item \textbf{Vector Memory Access:} Unit-stride (contiguous), strided (every Nth element), and indexed scatter/gather operations
    \item \textbf{Vector Permutation:} Instructions for shuffling data within and between vector registers
    \item \textbf{Masking and Predication:} Most vector instructions can be masked, performing operations only on elements where a corresponding bit in mask register \texttt{v0} is set
    \item \textbf{Reduction Operations:} Built-in support for combining all vector elements into a scalar result (sum, min, max, logical reductions)
\end{itemize}

\subsubsection{Programming with RISC-V Vector Intrinsics}

While assembly language provides direct control over vector instructions, RISC-V vector intrinsics offer a more maintainable and portable approach to vectorized programming. Intrinsics are C/C++ functions that map directly to vector instructions, providing the performance benefits of assembly with the readability and toolchain integration of high-level languages.

\textbf{Advantages of Intrinsics:}
\begin{itemize}
    \item \textbf{Compiler Integration:} Intrinsics work seamlessly with standard C/C++ compilers, enabling better optimization, register allocation, and instruction scheduling
    \item \textbf{Type Safety:} Unlike inline assembly, intrinsics are type-checked by the compiler, catching errors at compile time
    \item \textbf{Portability:} Code using intrinsics can be more easily ported across different RISC-V implementations
    \item \textbf{Maintainability:} Intrinsic-based code is more readable and easier to debug than raw assembly
\end{itemize}

\textbf{Common Intrinsic Patterns:}

\textit{Setting Vector Length:}
\begin{lstlisting}[language=C++]
size_t vl = __riscv_vsetvl_e32m1(n);
\end{lstlisting}

\textit{Vector Load/Store:}
\begin{lstlisting}[language=C++]
vfloat32m1_t v = __riscv_vle32_v_f32m1(ptr, vl);
__riscv_vse32_v_f32m1(ptr, v, vl);
\end{lstlisting}

\textit{Arithmetic Operations:}
\begin{lstlisting}[language=C++]
v_result = __riscv_vfadd_vv_f32m1(v1, v2, vl);
v_result = __riscv_vfmul_vf_f32m1(v, scalar, vl);
\end{lstlisting}

\textit{Fused Multiply-Accumulate:}
\begin{lstlisting}[language=C++]
v_acc = __riscv_vfmacc_vv_f32m1(v_acc, v1, v2, vl);
\end{lstlisting}

\textit{Reduction Operations:}
\begin{lstlisting}[language=C++]
vfloat32m1_t v_sum = __riscv_vfredsum_vs_f32m1_f32m1(v, v_zero, vl);
float sum = __riscv_vfmv_f_s_f32m1_f32(v_sum);
\end{lstlisting}

\subsection{Related Work: The RISC-V landscape for Vector Computing}

\paragraph{System-Level Infrastructure for RISC-V Vector Design}
The following papers focus on the modeling, simulation, verification, and reliability analysis infrastructure required to design and evaluate RISC-V vector-enabled systems before and during hardware implementation.

This subsection expands the descriptions for each of the selected papers to reflect their specific scientific contributions to the RISC-V and hardware--software co-design communities.

\subsubsection*{Herdt et al.: Extensible and Configurable RISC-V Virtual Prototype}

This paper introduces the first open-source, extensible \textbf{Virtual Prototype (VP)} based on the RISC-V architecture, implemented using standard-compliant \textbf{SystemC and TLM-2.0}. The primary scientific contribution is the creation of a middle-ground simulation environment that bridges the gap between high-speed but inflexible \textbf{Instruction Set Simulators (ISSs)} and highly accurate but extremely slow \textbf{Register Transfer Level (RTL)} models.

The VP architecture is built around a \textbf{RISC-V RV32IM core} and a generic bus system enabling easy platform reconfiguration. System-level features include a \textbf{PLIC-based interrupt controller}, a core-local interrupt controller (CLINT), and peripherals such as a DMA controller and a terminal.

Key \textbf{SystemC performance optimizations} include:
\begin{itemize}
    \item \textbf{Direct Memory Interface (DMI)} for bypassing bus transactions.
    \item \textbf{Temporal decoupling} to reduce simulation kernel synchronization overhead.
\end{itemize}

The VP achieves execution speeds of up to \textbf{20 million instructions per second}, several orders of magnitude faster than RTL simulation, enabling practical design space exploration.

\subsubsection*{Schlägl et al.: Unlocking Vector Processing for System-Level Evaluation}

Schlägl et al.\ present the first open-source SystemC TLM-based virtual prototype with full support for the \textbf{RISC-V Vector Extension (RVV) version~1.0}. The work addresses the lack of early-stage modeling tools capable of supporting the more than 600 vector instructions introduced by the standard.

A major contribution is an \textbf{automated instruction generation framework} that produces over \textbf{20,000 lines of C++ code}, ensuring consistency across RV32 and RV64 implementations. The resulting \textbf{RISC-V VP++} supports masking, register grouping, and widening/narrowing operations, as well as a parameterizable execution cycle model.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/Classic SIMD (ARM Neon) vs. Vector Architecture (RISC-V RVV).png}
    \caption{Classic SIMD (ARM Neon) vs. Vector Architecture (RISC-V RVV).}
    \label{fig:schlagel-rvv-vp}
\end{figure}

The authors validate correctness using a comprehensive verification chain combining FORCE-RISCV, Spike-based reference execution, and coverage analysis with riscvOVPsim, achieving 81.44\% basic coverage. Design-space exploration studies reveal non-linear performance scaling due to memory interface bottlenecks.

\subsubsection*{Quiroga et al.: Reusable Verification Environment for Vector Accelerators}

Quiroga et al.\ propose a \textbf{UVM-based, interface-agnostic verification environment} for RISC-V vector accelerators, enabling reuse across heterogeneous projects such as EPI and eProcessor.

The framework integrates constrained random generation via \textbf{RISCV-DV}, a Spike-based golden model using SystemVerilog DPI, and polymorphic wrappers to abstract interconnect protocols such as OVI and AMBA~CHI. This modularity reduces simulation overhead and enables early bug discovery during RTL development.

\subsubsection*{Imianosky et al.: Reliability and Performance of Vector Multiplication Units}

Imianosky et al.\ analyze performance--reliability trade-offs in fault-tolerant RISC-V systems by extending the \textbf{HARV-SoC} with \textbf{Zve32x} vector multiplication support.

Fault-injection experiments simulating neutron-induced single-event upsets show that vector acceleration achieves up to \textbf{28.69$\times$} speedup while often improving overall reliability due to reduced execution time. Reliability is shown to be highly dependent on \textbf{SEW}, with 8-bit configurations offering the most favorable trade-off.

\paragraph{Compiler, Application, and System-Level Performance Evaluation}
This group of papers evaluates how RISC-V vector capabilities translate into real-world performance across compilers, applications, memory-bound workloads, and high-performance computing systems, including machine learning workloads.

\subsubsection*{Wang et al.: SPEED --- Scalable Multi-Precision DNN Processor}

Wang et al.\ propose \textbf{SPEED}, a scalable multi-precision DNN processor designed to overcome limitations of baseline RVV implementations. SPEED integrates a highly parameterized \textbf{Systolic Array Unit (SAU)} within each vector lane and introduces custom instructions to orchestrate data movement and computation.

Synthesized in 28\,nm technology, SPEED achieves area-efficiency improvements of \textbf{2.04$\times$} for 16-bit and \textbf{1.63$\times$} for 8-bit operations compared to the Ara processor.

\subsubsection*{Rumyantsev et al.: RVV Efficiency for ANN Algorithms}

Rumyantsev et al.\ investigate the use of RVV to accelerate \textbf{Approximate Nearest Neighbor (ANN)} algorithms such as IVFFlat, IVFPQ, and HNSW. Using RVV intrinsics on a Lichee Pi~4A platform, the optimized implementations achieve speedups of up to \textbf{2.58$\times$} over scalar baselines.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/performance.png}
    \caption{Performance acceleration from RVV optimization for various ANN algorithms on the Epsilon and GloVe datasets.}
    \label{fig:rvv-ann-performance}
\end{figure}

\subsubsection*{Carpentieri et al.: Performance Analysis of Autovectorization on RVV Boards}

Carpentieri et al.\ present an empirical evaluation of \textbf{compiler-driven autovectorization} on real RISC-V hardware, comparing GCC and LLVM across TSVC benchmarks and real-world applications.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/Geometric mean of speedup.png}
    \caption{Geometric mean of speedup achieved through autovectorization across different loop categories and compilers using
RVV 1.0.}
    \label{fig:carpentieri-autovec}
\end{figure}

The study shows that \textbf{Vector Length Specific (VLS)} programming often outperforms VLA due to reduced runtime overhead, and that careful tuning of \textbf{LMUL} can yield speedups of up to \textbf{3$\times$}. LLVM~19 outperforms GCC~14 in most benchmark cases, though higher LMUL values can increase register pressure.

\subsubsection*{Volokitin et al.: Memory-Bound Kernels on RISC-V CPUs}

Volokitin et al.\ evaluate memory-bound kernels on RISC-V platforms and show that classical optimizations such as cache blocking and unit-stride access transfer effectively from x86 and ARM architectures. Despite lower absolute bandwidth, RISC-V systems demonstrate high memory subsystem utilization efficiency.

\subsubsection*{Brown: Evaluating the Sophon SG2044 for High Performance Computing}

Brown evaluates RISC-V’s suitability for \textbf{High Performance Computing} through an analysis of the \textbf{Sophon SG2044}. With mainline RVV~1.0 support and a 32-channel DDR5 memory subsystem, the SG2044 achieves up to a \textbf{4.91$\times$} speedup over its predecessor, positioning RISC-V as a competitive architecture for multi-core server workloads.
