\section{Background \& Related Work}

This chapter provides the foundational context necessary to understand the architectural innovations explored in this project. It begins by introducing the RISC-V ISA, highlighting the design philosophies—such as modularity and open-source extensibility—that make it a disruptive force in the processor industry. The discussion then narrows to the specific technical specifications of the RISC-V Vector (RVV) extension, detailing the mechanisms of Vector-Length Agnosticism and programming through intrinsics. Finally, a review of related work establishes the current state of the art in system-level simulation, hardware acceleration, and performance benchmarking within the RISC-V ecosystem.

\subsection{RISC-V Architecture Overview}

RISC-V (pronounced ``risk-five'') is an open-source ISA that has revolutionized processor design by providing a free, extensible alternative to proprietary architectures. Developed at the University of California, Berkeley, beginning in 2010 \cite{riscv-v-spec}, RISC-V was created to address fundamental limitations in the processor industry, particularly the dominance of proprietary ISAs that created barriers to innovation and increased costs for processor development.

The development of RISC-V was motivated by several critical issues in the computing industry that had become increasingly problematic for AI and DSP applications. Traditional proprietary ISAs, such as x86 and ARM, require expensive licensing agreements that can be prohibitive for companies developing specialized processors for AI and DSP workloads. These licensing costs are particularly burdensome for startups and research institutions that want to experiment with novel architectural approaches.

RISC-V addresses these challenges through several fundamental design principles that make it particularly well-suited for AI and DSP applications:

\textbf{Open Source Philosophy:} RISC-V specifications are freely available under Creative Commons licenses, and anyone can implement, modify, or extend RISC-V processors without paying royalties or obtaining permission. This openness eliminates one of the major barriers to innovation in processor design and enables a diverse ecosystem of implementations tailored for specific applications.

\textbf{Modular Architecture:} RISC-V follows a modular design philosophy where a minimal base integer instruction set is supplemented by optional standard extensions. This modularity is particularly valuable for AI and DSP processors, which can include only the extensions needed for their specific applications, reducing implementation complexity and cost.

\textbf{Scalability Across Application Domains:} RISC-V supports multiple data widths (32-bit, 64-bit, and 128-bit) and can scale from microcontrollers to high-performance processors. This scalability is crucial for AI and DSP applications, which span a wide range of computing environments from embedded edge devices to high-performance computing clusters.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/growth.png}
    \caption[RISC-V ecosystem growth]{RISC-V ecosystem growth. Source: Semico Research Corp. \cite{semico2023riscv}}
    \label{fig:growth}
\end{figure}    

\subsection{RISC-V Extensions for Machine Learning}

The extensible nature of RISC-V is fundamental to its success in AI and DSP applications, allowing specialized functionality to be added to the base instruction set through a well-defined extension mechanism. This extensibility enables processors to be tailored for specific application domains while maintaining compatibility with the broader RISC-V ecosystem.

\subsubsection{Standard Extensions}

The modular nature of RISC-V allows the base integer ISA to be supplemented with standard extensions to meet the requirements of specific application domains:

\begin{itemize}
    \item \textbf{M Extension (Integer Multiplication and Division):} Adds hardware support for integer multiplication and division. This is essential for quantized neural networks and DSP algorithms where integer arithmetic is used to minimize power consumption.
    
    \item \textbf{F Extension (Single-Precision Floating-Point):} Provides IEEE 754 32-bit floating-point arithmetic. It introduces Fused Multiply-Add (FMA) instructions, which are critical for the multiply-accumulate (MAC) patterns dominant in convolution operations.
    
    \item \textbf{D Extension (Double-Precision Floating-Point):} Adds 64-bit floating-point support, necessary for AI training phases requiring high numerical stability and DSP applications with extended dynamic range requirements.
    
    \item \textbf{V Extension (Vector Operations):} The primary focus of this project, providing comprehensive support for data-parallel operations through a vector-length agnostic architecture. It enables high-throughput execution for the tensor and matrix operations found in modern AI workloads.
\end{itemize}

\subsection{The RISC-V Vector Extension}

The RISC-V Vector (RVV) Extension stands out as one of the most consequential developments for modern computing workloads. Unlike traditional Single Instruction, Multiple Data (SIMD) architectures that operate on fixed-size registers, RVV was designed with a philosophy of flexibility, scalability, and efficiency achieved through novel architectural concepts.

\subsubsection{Architectural Principles}

\textbf{Vector Registers and Configuration:} The V extension introduces 32 vector registers (\texttt{v0}--\texttt{v31}). The core architectural parameter is VLEN (Vector Length), which specifies the length of these registers in bits. VLEN is an implementation-defined choice, not fixed by the specification, and can range from small values (e.g., 128 bits) for embedded systems to very large values (e.g., 4096 bits or more) for supercomputers. Another key parameter is ELEN (Element Length), which is the maximum size of a single data element that can be processed.

\textbf{Vector Control and Status Registers (CSRs):} The power and flexibility of the V extension are managed through key Control and Status Registers:

\begin{itemize}
    \item \texttt{vtype}: Configures the vector unit for subsequent operations by setting the selected element width (\texttt{vsew}), vector length multiplier (\texttt{vlmul}) for register grouping, and behavior controls for tail and masked-out elements (\texttt{vta}/\texttt{vma}).
    \item \texttt{vl}: Set by the programmer to specify the number of elements to process in upcoming vector instructions, ranging from 0 to a hardware-dependent maximum.
    \item \texttt{vlenb}: A read-only register that reports the hardware's vector register length (VLEN) in bytes.
\end{itemize}

\textbf{Vector-Length Agnostic (VLA) Execution:} The combination of the \texttt{vsetvli} instruction and the \texttt{vl} register enables RVV's most powerful feature: Vector-Length Agnosticism. Unlike fixed-length SIMD (e.g., Intel's AVX or ARM's NEON), where code is written for a specific vector width, VLA code is portable across any hardware implementation, regardless of its VLEN.

The typical execution flow follows a ``strip-mining'' pattern:
\begin{enumerate}
    \item A programmer has a large array of N elements to process
    \item The code enters a loop and calls \texttt{vsetvli}, passing the remaining number of elements
    \item The hardware automatically sets \texttt{vl} to the minimum of the requested number and the maximum it can physically handle (VMAX), configuring \texttt{vtype} appropriately
    \item Subsequent vector instructions operate on \texttt{vl} elements
    \item The loop continues, processing chunks of data until all N elements are complete
\end{enumerate}

This approach means a single compiled binary can run with optimal efficiency on both a low-power microcontroller with VLEN=128 and a high-performance compute node with VLEN=4096, without requiring recompilation or code modification.

\textbf{Rich and Orthogonal Instruction Set:} The V extension provides a comprehensive set of instructions orthogonal to data types, allowing the same opcodes to work on integers and floats of different widths as configured by \texttt{vtype}. Key instruction categories include:

\begin{itemize}
    \item \textbf{Vector Arithmetic:} Integer, fixed-point, and floating-point operations
    \item \textbf{Vector Memory Access:} Unit-stride (contiguous), strided (every Nth element), and indexed scatter/gather operations
    \item \textbf{Vector Permutation:} Instructions for shuffling data within and between vector registers
    \item \textbf{Masking and Predication:} Most vector instructions can be masked, performing operations only on elements where a corresponding bit in mask register \texttt{v0} is set
    \item \textbf{Reduction Operations:} Built-in support for combining all vector elements into a scalar result (sum, min, max, logical reductions)
\end{itemize}

\subsubsection{Programming with RISC-V Vector Intrinsics}

While assembly language provides direct control over vector instructions, RISC-V vector intrinsics offer a more maintainable and portable approach to vectorized programming. Intrinsics are C/C++ functions that map directly to vector instructions, providing the performance benefits of assembly with the readability and toolchain integration of high-level languages.

\noindent \textbf{Advantages of Intrinsics:}
\begin{itemize}
    \item \textbf{Compiler Integration:} Intrinsics work seamlessly with standard C/C++ compilers, enabling better optimization, register allocation, and instruction scheduling
    \item \textbf{Type Safety:} Unlike inline assembly, intrinsics are type-checked by the compiler, catching errors at compile time
    \item \textbf{Portability:} Code using intrinsics can be more easily ported across different RISC-V implementations
    \item \textbf{Maintainability:} Intrinsic-based code is more readable and easier to debug than raw assembly
\end{itemize}

\vspace{3pt}
\noindent \textbf{Common Intrinsic Patterns:}
\vspace{3pt}

\textit{Setting Vector Length:}
\begin{lstlisting}[language=C++]
size_t vl = __riscv_vsetvl_e32m1(n);
\end{lstlisting}

\textit{Vector Load/Store:}
\begin{lstlisting}[language=C++]
vfloat32m1_t v = __riscv_vle32_v_f32m1(ptr, vl);
__riscv_vse32_v_f32m1(ptr, v, vl);
\end{lstlisting}

\textit{Arithmetic Operations:}
\begin{lstlisting}[language=C++]
v_result = __riscv_vfadd_vv_f32m1(v1, v2, vl);
v_result = __riscv_vfmul_vf_f32m1(v, scalar, vl);
\end{lstlisting}

\textit{Fused Multiply-Accumulate:}
\begin{lstlisting}[language=C++]
v_acc = __riscv_vfmacc_vv_f32m1(v_acc, v1, v2, vl);
\end{lstlisting}

\textit{Reduction Operations:}
\begin{lstlisting}[language=C++]
vfloat32m1_t v_sum = __riscv_vfredsum_vs_f32m1_f32m1(v, v_zero, vl);
float sum = __riscv_vfmv_f_s_f32m1_f32(v_sum);
\end{lstlisting}

\subsection{Related Work: The RISC-V landscape for Vector Computing}

\paragraph{System-Level Infrastructure for RISC-V Vector Design} The following papers focus on the modeling, simulation, verification, and reliability analysis infrastructure required to design and evaluate RISC-V vector-enabled systems before and during hardware implementation.

\subsubsection*{Herdt et al.: Extensible and Configurable RISC-V Virtual Prototype}

Herdt et al. \cite{herdt2018extensible} introduces the first open-source, extensible \textbf{Virtual Prototype (VP)} based on the RISC-V architecture, implemented using standard-compliant SystemC and Transaction-Level Modeling \textbf{(TLM-2.0)}.. The primary scientific contribution is the creation of a middle-ground simulation environment that bridges the gap between high-speed but inflexible \textbf{Instruction Set Simulators (ISSs)} and highly accurate but extremely slow \textbf{Register Transfer Level (RTL)} models.

\subsubsection*{Schlägl et al.: Unlocking Vector Processing for System-Level Evaluation}

Schlägl et al. \cite{schlaegl2024riscv} present the first open-source SystemC TLM-based virtual prototype with full support for the \textbf{RISC-V Vector Extension (RVV) version 1.0}. The work addresses the lack of early-stage modeling tools capable of supporting the more than 600 vector instructions introduced by the standard.

\subsubsection*{Quiroga et al.: Reusable Verification Environment for Vector Accelerators}

Quiroga et al. \cite{quiroga2022reusable} propose a \textbf{Universal Verification Methodology (UVM)-based, interface-agnostic verification environment} for RISC-V vector accelerators, enabling reuse across heterogeneous projects such as EPI and eProcessor.

\subsubsection*{Imianosky et al.: Reliability and Performance of Vector Multiplication Units}

Imianosky et al. \cite{imianosky2024reliability} analyze performance--reliability trade-offs in fault-tolerant RISC-V systems by extending the \textbf{HARV-SoC} with \textbf{Zve32x} vector multiplication support. Fault-injection experiments show that vector acceleration achieves up to \textbf{28.69$\times$} speedup while often improving overall reliability due to reduced execution time.

\paragraph{Compiler, Application, and System-Level Performance Evaluation} This group of papers evaluates how RISC-V vector capabilities translate into real-world performance across compilers, applications, and high-performance computing systems.

\subsubsection*{Al-Assir et al.: Arrow RISC-V Vector Accelerator} Al-Assir et al. \cite{alassir2021arrow} present \textbf{Arrow}, a RISC-V vector accelerator optimized for machine learning inference. By focusing on a configurable architecture that supports different vector lengths and data types, Arrow demonstrates significant energy efficiency and throughput gains for edge-based ML tasks compared to scalar implementations.

\subsubsection*{Wang et al.: SPEED --- Scalable Multi-Precision DNN Processor}

Wang et al. propose \textbf{SPEED}, a scalable multi-precision Deep Neural Network (DNN) processor designed to overcome limitations of baseline RVV implementations. SPEED integrates a highly parameterized \textbf{Systolic Array Unit (SAU)} within each vector lane. Synthesized in 28,nm technology, SPEED achieves area-efficiency improvements of \textbf{2.04$\times$} for 16-bit and \textbf{1.63$\times$} for 8-bit operations compared to the Ara processor \cite{wang2024speed}.

\subsubsection*{Carpentieri et al.: Performance Analysis of Autovectorization on RVV Boards}

Carpentieri et al. \cite{carpentieri2025performance} present an empirical evaluation of \textbf{compiler-driven autovectorization} on real RISC-V hardware, comparing GCC and LLVM across Test Suite for Vectorizing Compilers (TSVC) benchmarks and real-world applications. The study shows that careful tuning of \textbf{LMUL} can yield speedups of up to \textbf{3$\times$}.

\subsubsection*{Volokitin et al.: Memory-Bound Kernels on RISC-V CPUs}

Volokitin et al. \cite{volokitin2023case} evaluate memory-bound kernels on RISC-V platforms and show that classical optimizations such as cache blocking and unit-stride access transfer effectively from x86 and ARM architectures.

\subsubsection*{Brown: Evaluating the Sophon SG2044 for High Performance Computing}

Brown \cite{brown2025riscv} evaluates RISC-V’s suitability for \textbf{High Performance Computing} through an analysis of the \textbf{Sophon SG2044}. With mainline RVV 1.0 support and a 32-channel DDR5 memory subsystem, the SG2044 achieves up to a \textbf{4.91$\times$} speedup over its predecessor.\\[2pt]

In summary, this chapter has established the architectural and scholarly framework for the thesis. By reviewing the modular nature of RISC-V and the unique "vector-length agnostic" capabilities of the RVV extension, we have identified how this ISA overcomes the rigid limitations of traditional SIMD architectures. The exploration of related work highlights a robust and growing ecosystem of simulation tools and specialized accelerators, yet it also underscores the ongoing need for optimization in machine learning and DSP kernels. These insights provide the necessary baseline for the implementation and evaluation phases that follow in this project.