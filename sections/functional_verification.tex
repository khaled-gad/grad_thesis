% !TEX root = ../Thesis.tex

\subsection{Functional Verification Results and Discussion}

\subsubsection{Test Setup and Verification Flow}

To ensure the correctness and reliability of the vectorized ML kernels implemented using the RISC-V Vector Extension (RVV), a comprehensive functional verification methodology was established. The verification process validates that the custom C++ implementations produce numerically equivalent results to industry-standard machine learning frameworks, specifically using ONNX Runtime as the golden reference.

\subsubsection{Verification Architecture}

The verification flow follows a dual-path approach comparing the RVV-vectorized kernels against ONNX Runtime inference results. Figure~\ref{fig:verification_flow} illustrates the complete verification architecture, which consists of two parallel execution paths:

\textbf{Path 1: RVV Implementation Path}
\begin{enumerate}
    \item Design and implement vectorized kernels using C++ with RISC-V Vector intrinsics
    \item Implement corresponding scalar kernel versions for reference
    \item Execute kernels and save results in binary (.bin) files for comparison
\end{enumerate}

\textbf{Path 2: ONNX Golden Reference Path}
\begin{enumerate}
    \item Generate ONNX model/graph representing the same operation
    \item Import the ONNX model in Python using ONNX Runtime
    \item Run inference to obtain golden reference results
\end{enumerate}

The outputs from both paths are then compared using quantitative metrics to assess functional correctness. This dual-path methodology ensures that the RVV implementations conform to the mathematical specifications of standard ML operations.

% Uncomment and adjust path when you add the figure
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.55\textwidth]{figures/func verification flow.png}
    \caption{Functional verification flow diagram}
    \label{fig:verification_flow}
\end{figure}

\subsubsection{Verification Metrics}

To quantitatively assess the functional correctness of the RVV-vectorized kernels, two primary metrics were employed: Signal-to-Noise Ratio (SNR) and Maximum Absolute Error. These metrics provide complementary perspectives on numerical accuracy.

\paragraph{Signal-to-Noise Ratio (SNR)}

The Signal-to-Noise Ratio provides a relative measure of the accuracy of the RVV implementation compared to the golden reference. It is calculated using the following formula:

\begin{equation}
\text{SNR} = 10 \times \log_{10}\left(\frac{\sum y_i^2}{\sum (y_i - \hat{y}_i)^2}\right)
\label{eq:snr}
\end{equation}

where:
\begin{itemize}
    \item $y_i$ = ONNX golden reference output values
    \item $\hat{y}_i$ = RVV implementation output values
    \item $\sum$ denotes summation over all output elements
\end{itemize}

A higher SNR indicates better agreement between the RVV implementation and the golden reference. For floating-point operations, an SNR above 90~dB is generally considered excellent, indicating that the error is negligible compared to the signal magnitude. For fixed-point and integer operations, the acceptable threshold may vary depending on the data representation and bit width.

\paragraph{Maximum Absolute Error}

The Maximum Absolute Error provides an absolute measure of the worst-case deviation between the RVV implementation and the golden reference:

\begin{equation}
\text{Max Absolute Error} = \max_i |y_i - \hat{y}_i|
\label{eq:max_error}
\end{equation}

% should an example be added here?
This metric is particularly important for identifying outliers and worst-case scenarios. While SNR provides an overall measure of accuracy, the maximum absolute error ensures that no individual output value deviates significantly from the expected result. For functional correctness, it is crucial that this error remains within acceptable numerical precision bounds, typically on the order of machine epsilon for the given data type multiplied by the computational depth of the operation.

\subsubsection{Verification Thresholds}

To determine whether a kernel passes functional verification, the following thresholds were established based on numerical precision characteristics of different data types and operation complexity:

\begin{table}[htbp]
\centering
\caption{Verification threshold criteria for different data types and operation complexities}
\label{tab:verification_thresholds}
\begin{tabular}{@{}llcc@{}}
\toprule
\textbf{Data Type} & \textbf{Operation} & \textbf{Min SNR (dB)} & \textbf{Max Abs Error} \\ 
\midrule
FP32 & Simple & $> 100$ & $< 10^{-6}$ \\
FP32 & Complex & $> 80$ & $< 10^{-5}$ \\
FP64 & Any & $> 120$ & $< 10^{-12}$ \\
INT8/INT16 & Any & $> 60$ & $= 0$ \\
INT32 & Any & $> 80$ & $= 0$ \\
\bottomrule
\end{tabular}
\end{table}

These thresholds account for the inherent numerical precision limitations of different data types as well as the accumulation of rounding errors in complex operations such as matrix multiplications or multi-stage computation pipelines.

