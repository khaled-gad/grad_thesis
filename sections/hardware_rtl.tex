% !TEX root = ../Thesis.tex
\subsection{Hardware (RTL Cores)}

In the rigorous domain of computer architecture research, particularly within the context of next-generation machine learning (ML) workload acceleration, the simulation environment serves as the foundational bedrock for all performance claims and design space explorations. While high-level functional simulators—such as Spike or QEMU—provide a mechanism for validating instruction set architecture (ISA) compliance and functional correctness, they fundamentally lack the temporal fidelity required to model complex microarchitectural phenomena.

\subsubsection{Role of RTL Cores in Architectural Research}

For a graduation thesis focused on the benchmarking of RISC-V vector architectures, relying solely on functional simulation would obscure critical bottlenecks such as pipeline hazards, register file banking conflicts, memory interconnect contention, and the latency costs associated with control flow divergence. Register Transfer Level (RTL) cores, therefore, play an indispensable role. They offer a bit-accurate and cycle-accurate representation of the hardware, synthesized from languages such as System Verilog.

Simulation at this level allows the researcher to observe the precise interaction between the scalar host processor and the vector accelerator, capturing the ``handshake'' overheads that are often idealized in abstract models. Furthermore, RTL simulation is the only methodology capable of generating credible Power, Performance, and Area (PPA) metrics. By simulating the actual hardware description that would eventually be mapped to silicon or Field-Programmable Gate Arrays (FPGAs), researchers can derive energy efficiency numbers (e.g., FLOPS/Watt) and area utilization statistics (e.g., gate counts or LUT usage) that are grounded in physical reality rather than theoretical estimation.

For machine learning workloads, which are characteristically defined by dense linear algebra operations (GEMM), convolutions (CONV2D), and high-bandwidth memory access patterns, RTL cores reveal the true utilization of functional units (FUs). They allow for the precise measurement of ``raw throughput ideality''—a metric comparing achieved performance against theoretical peaks—and facilitate the identification of non-obvious bottlenecks, such as the scalar core's instruction issue rate limiting the performance of short-vector kernels.

\subsubsection{Importance of Cycle-Accurate Simulation}

The evaluation of vectorized ML kernels requires a simulation environment that can faithfully model the behavior of the RISC-V Vector (RVV) extension. The RVV specification introduces a paradigm of data-level parallelism that is significantly more complex than traditional SIMD (Single Instruction, Multiple Data) approaches found in fixed-width architectures. Features such as Vector Length Agnosticism (VLA), dynamic Element Width (SEW) grouping (LMUL), and masked execution create a vast design space where theoretical efficiency does not always translate to realized performance.

Cycle-accurate simulation is paramount for evaluating these kernels because it exposes the latency penalties associated with microarchitectural housekeeping. For instance, the ``strip-mining'' loops common in ML kernels require the hardware to dynamically adjust the vector length (\texttt{vsetvli}) and handle potentially misaligned memory accesses. An RTL simulation reveals the setup time of the vector pipeline, the latency of the Vector Load/Store Unit (VLSU) when handling strided accesses (common in tensor operations), and the impact of coherent cache hierarchies on memory bandwidth.

Without cycle-accurate visibility, a researcher might overestimate the performance of a matrix multiplication kernel by failing to account for the cycles lost to cache invalidations or the serialization of micro-operations within the vector unit. Moreover, ML workloads often exhibit phases of computation that are distinct: memory-bound phases (e.g., activation loading) and compute-bound phases (e.g., matrix accumulation). RTL cores allow for the construction of ``Roofline'' models based on empirical data, plotting arithmetic intensity against achieved floating-point operations per second.

\subsubsection{Evolution of Core Selection: From Vicuna to Ara}

The selection of RTL cores for this research followed an iterative process driven by the increasing complexity of the targeted machine learning (ML) workloads. Initially, \textbf{Vicuna} was selected as the primary benchmarking vehicle due to its focus on the \textbf{Zve32x} integer extension and its suitability for lightweight FPGA implementation. However, as the research progressed into high-fidelity ML acceleration—specifically requiring IEEE-754 floating-point support and the full range of \textbf{RVV 1.0} instructions—the limitations of an embedded-class core became apparent.

While Vicuna served as a robust baseline for integer-only quantized kernels, it lacked the Vector Floating-Point Units ($VFPU$) necessary for modern inference and training benchmarks. This necessitated a transition to \textbf{Ara}, a significantly more powerful and flexible architecture. Unlike the embedded constraints of Vicuna, Ara supports the full $64$-bit floating-point spectrum and provides a much more sophisticated RTL simulation environment, offering higher temporal fidelity and parametric scalability.

Due to these architectural requirements, the methodology for the performance validation phase of this thesis was refined. While both cores are analyzed to represent the diversity of the RISC-V vector ecosystem, the actual benchmarking of complex, compute-intensive kernels—such as $Conv2D$, $MaxPool$, and $ReLU$—is performed exclusively on the \textbf{Ara} core. This approach ensures that the benchmarking suite can evaluate the hardware's ability to handle the high arithmetic intensity and precision demands characteristic of modern neural network layers, which remain outside the functional scope of integer-only embedded cores.

% ------------------------------------------------------------
% Vicuna Vector Processor
% ------------------------------------------------------------

\subsection{Vicuna RISC-V Vector Coprocessor}

\subsubsection{Overview and Design Motivation}

Vicuna is a 32-bit vector coprocessor designed to fill a distinct niche in the RISC-V ecosystem: timing predictability. While most vector processors maximize average-case throughput using caches, out-of-order execution, and banking, these features introduce ``timing anomalies''—situations where a local speedup results in a global slowdown due to pipeline scheduling effects. Vicuna's primary purpose is to serve real-time systems (e.g., automotive ADAS, avionics) where the Worst-Case Execution Time (WCET) must be strictly bounded and analyzable.

Despite its focus on predictability, Vicuna does not sacrifice scalability. It is designed to scale its performance linearly with the number of execution units while maintaining a simple, analyzable timing model. It specifically targets the Zve32x extension—a subset of RVV 1.0 intended for embedded processors that require vectorization for integer workloads (like quantized neural networks) but do not need 64-bit elements or floating-point support.

\subsubsection{Architectural Organization}

Vicuna acts as a coprocessor to a main scalar core. The reference integration uses the Ibex core (a small, efficient 2-stage RISC-V core) or the CV32E40X. Communication is handled via the OpenHW Group's CORE-V eXtension Interface (XIF), where the main core fetches instructions and dispatches valid vector instructions to Vicuna.

Vicuna is highly configurable, allowing for independent scaling of the architectural vector length (VLEN) and the physical datapath width (VPIPE\_W). To minimize logic consumption on FPGAs, Vicuna avoids complex sub-word selection multiplexers; instead, it utilizes operand shift registers to feed functional units. Source vector registers are read entirely into these buffers and shifted into the processing pipeline cycle-by-cycle. Furthermore, to eliminate the timing unpredictability of bank conflicts, the Vector Register File (VRF) is implemented as a multi-ported XOR-based RAM rather than a banked architecture. This ensures that register access latency remains constant regardless of the instruction sequence or data pattern.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{figures/Vicuna.jpg}
\caption{Overview of Vicuna's architecture and its integration with the Ibex main core. Both cores share a common data cache with predictable memory arbitration ensuring deterministic timing behavior.}
\label{fig:vicuna_diagram}
\end{figure}

Vicuna executes vector instructions using a dedicated set of functional units: a Vector Load/Store Unit (VLSU) for memory traffic, a Vector ALU (VALU) for integer arithmetic and logic, a Vector Multiplier (VMUL) for integer multiplication, and Vector Slide (VSLD) and Element (VELEM) units for permutations and reductions. The control logic is designed to be monotonic, ensuring that the progress of an instruction is never hindered by a subsequent instruction—a key requirement for preventing timing anomalies.

\subsubsection{RVV Implementation}

Vicuna implements the RVV 1.0 (Zve32x) extension profile with support for 8-bit, 16-bit, and 32-bit integers. It explicitly excludes floating-point operations and 64-bit element support, which reduces area and complexity while aligning with its embedded target. Vicuna supports configurable vector register lengths (VLEN), typically synthesized with 512-bit sizes in FPGA tests, and handles Element Widths (SEW) of 8, 16, and 32 bits. The execution model ensures that the processing time for a vector of length $N$ is a deterministic function of $N$ and the number of execution units, enabling precise WCET calculation.

\subsubsection{Execution Model}

Vicuna’s execution model is formally grounded in timing monotonicity. The pipeline is modeled across seven abstract stages: \textit{pre}, \textit{IF}, \textit{ID+EX}, \textit{VQ} (Vector Queue), \textit{VEU} (Vector Execution Units), \textit{postS}, and \textit{postV}. This structure ensures that any pipeline stage can only be stalled by a subsequent stage in the program order, effectively preventing timing anomalies (where a local speedup, such as a cache hit, results in a global execution delay). This monotonic behavior is a sufficient condition for compositional timing analysis, enabling the derivation of a tight Worst-Case Execution Time (WCET) that is mathematically guaranteed to be the maximum possible latency.

Parallelism in Vicuna is achieved through simultaneous and successive processing. Multiple elements are processed in a single cycle if the data path width allows (e.g., processing four 8-bit elements on a 32-bit datapath). For vectors longer than the datapath width, the unit processes chunks sequentially over multiple cycles, amortizing the instruction fetch cost through temporal vectorization.

\subsubsection{Memory Subsystem}

Vicuna supports the standard RVV memory access patterns: unit-stride, strided, and indexed (scatter/gather). Vicuna maintains memory predictability through a strict-ordering memory arbiter governing a shared 2-way LRU data cache. To prevent the scalar core from interfering with vector timing, the arbiter always grants precedence to vector accesses. Crucially, it prevents \textit{amplification timing anomalies} by delaying any scalar access following a cache miss until all pending vector load/store operations are completed. This mechanism ensures that the memory interface—typically a source of non-determinism—behaves in a strictly predictable manner, allowing the scalar core to stall only for a bounded, deterministic number of cycles during vector memory activity.

\subsubsection{RTL Implementation}

Vicuna is implemented in SystemVerilog with a focus on FPGA deployment, particularly the Xilinx 7 Series. The design is compact, with resource utilization (LUTs and Flip-Flops) comparable to other soft-core vector processors like VESPA or VEGAS, yet offering higher performance due to its pipelining and RVV compliance. On a Xilinx 7 Series FPGA, Vicuna achieves a clock frequency of 80 MHz with a peak throughput of 10.24 billion operations per second for 8-bit operations (128 MACs/cycle).

The verification strategy for Vicuna focuses on proving timing constancy using Verilator, Questasim, and xsim. The primary verification metric is that benchmarks (e.g., matmul) must execute in the exact same number of cycles for every run, regardless of input data values. This confirms the absence of timing anomalies through repeated validation using a suite of benchmarks (AXPY, CONV2D, GEMM).

\subsubsection{Benchmarking Suitability}

Vicuna represents the \textit{predictable-efficiency} design point in the benchmarking suite. While timing-predictable multi-core systems (e.g., T-CREST) typically scale performance logarithmically due to interconnect contention, Vicuna’s performance scales linearly with its datapath width. In compute-bound kernels such as GEMM, Vicuna achieves a multiplier utilization exceeding 90\% (reaching up to 99.5\% in smaller configurations), significantly outperforming other soft-vector processors like VEGAS (49\%). This efficiency proves that the removal of non-deterministic optimizations (e.g., out-of-order write-back, banked VRFs) does not result in a significant performance penalty for data-parallel tasks, making it a robust baseline for 8-bit quantized edge AI applications.

% ------------------------------------------------------------
% Ara Vector Processor
% ------------------------------------------------------------

\subsection{Ara Vector Processor}

\subsubsection{Overview and Design Motivation}

Ara is a 64-bit vector processor designed for high-throughput, energy-efficient execution of data-parallel workloads. Unlike Vicuna’s focus on timing predictability, Ara is optimized for maximal floating-point utilization, making it suitable for High-Performance Computing (HPC) and Machine Learning (ML) applications. It implements the full RVV 1.0 specification, supporting a wide range of data types from 64-bit double-precision floating-point values down to 8-bit integers.

Ara operates as a coprocessor tightly coupled with a scalar host core, typically CVA6 (formerly Ariane). Its primary architectural goal is to amortize the instruction fetch and decode costs of the scalar core across long vector sequences, achieving a high ratio of FLOPS per Watt. The design explicitly draws inspiration from classical vector supercomputers such as the Cray-1, as well as contemporary systems like the Fugaku A64FX processor, positioning Ara as an open-source RISC-V vector architecture for the exascale era.

Ara's architectural evolution—most notably the transition from Ara to Ara2—was driven by two main objectives: strict compliance with the ratified RISC-V Vector Extension version 1.0 (RVV 1.0) and aggressive scaling of floating-point throughput. This evolution required substantial microarchitectural changes to support dynamic vector length configuration, masking semantics, and mixed element widths, while enabling parametric scaling across a wide range of performance and power targets.

\subsubsection{Architectural Organization}

The Ara system operates as a coherent vector coprocessor tightly integrated with the CVA6 scalar core. CVA6 manages the control plane, including instruction fetch, control flow, and exception handling. Vector instructions are dispatched to Ara only after they are committed in the scalar pipeline, ensuring non-speculative execution and simplifying the vector unit’s control logic by eliminating rollback requirements due to branch mispredictions.

Ara’s microarchitecture is composed of $N$ identical vector lanes, where $N$ is typically a power of two ($2, 4, 8, 16$). Each lane contains a proportional slice of the Vector Register File (VRF) and a set of functional units, including a Vector ALU (VALU) and a Vector Floating-Point Unit (VFPU). To provide high register bandwidth without incurring the area cost of multi-ported memories, Ara implements a \emph{barber-pole} banking scheme. In this layout, vector elements are distributed across banks and lanes such that, for most element-wise operations, operands are locally available within each lane, minimizing cross-lane data movement.

This banking strategy allows Ara to achieve high VRF bandwidth using simple single-port SRAMs while maintaining scalability. Consecutive vector elements are striped across lanes (e.g., element 0 in lane 0, element 1 in lane 1), enabling the processor to execute up to $N$ operations per cycle for fully vectorized workloads.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{figures/ara.jpg}
\caption{Top-level block diagram of the Ara2 system showing the vector coprocessor, lane-based organization, and integration with the CVA6 scalar core.}
\label{fig:ara_diagram}
\end{figure}

\subsubsection{RVV Implementation}

Ara fully implements the frozen RVV 1.0 extension with comprehensive feature support:

\begin{itemize}
    \item \textbf{Data Types:} IEEE-754 floating-point formats (FP16, FP32, FP64) and standard integer types (INT8, INT16, INT32, INT64)
    \item \textbf{Reductions:} Support for ordered and unordered vector reductions, including floating-point reductions requiring precise control of execution order
    \item \textbf{Masking:} Full support for masked execution, enabling element-wise predication through dedicated mask registers
    \item \textbf{Permutations:} Support for permutation instructions such as \texttt{vslideup}, \texttt{vslidedown}, \texttt{vgather}, and \texttt{vscatter} via a dedicated on-chip interconnect
\end{itemize}

\subsubsection{Vector Execution Model}

Ara adheres to the Vector Length Agnostic (VLA) programming model mandated by the RISC-V specification. While the hardware vector length (VLEN) is fixed per instantiation, software binaries remain portable across implementations. At runtime, the \texttt{vsetvli} instruction configures the application vector length (AVL), which is automatically distributed across the available lanes. If the AVL exceeds the number of parallel lanes, the hardware transparently strip-mines the operation, executing the vector in temporal chunks.

While element-wise instructions execute independently within each lane, operations involving data movement—such as reductions, masking, and permutations—are handled by centralized Mask and Permutation Units. These operations require cross-lane communication and are implemented using an $O(L \log L)$ interconnect, where $L$ is the number of lanes.

For reduction operations, Ara employs a three-step algorithm: first, partial reductions are performed locally within each lane; second, cross-lane shuffling aligns partial results; finally, the scalar result is written back to the destination register. This decoupled execution model allows arithmetic pipelines to remain highly utilized while centralized units manage irregular data access patterns.

Ara supports vector chaining, enabling dependent instructions to begin execution before their predecessors have fully completed, provided that the required operands are available. This capability is essential for sustaining high utilization of deep floating-point pipelines in sequences such as fused multiply-accumulate (\texttt{vfmacc}) operations.

\subsubsection{Memory Subsystem}

The Vector Load/Store Unit (VLSU) serves as the interface between the high-bandwidth AXI memory system and the vector lanes. It supports unit-stride, strided, and indexed (scatter/gather) memory accesses and is responsible for routing memory data to the appropriate lanes and VRF banks. Due to its flexible routing requirements, the complexity of the VLSU scales superlinearly with the number of lanes.

Ara2 introduces a robust hardware coherence mechanism between the scalar and vector domains. The CVA6 data cache operates in write-through mode, ensuring that scalar stores are immediately visible to Ara. Conversely, vector stores issued by Ara generate invalidation signals to the CVA6 cache, forcing eviction of affected cache lines. This hardware-based scheme eliminates the need for software-managed fence instructions while maintaining a coherent memory view across scalar and vector execution.

\subsubsection{RTL Implementation}

Implemented in GlobalFoundries 22FDX (22nm FD-SOI) technology, Ara (in its Ara2 iteration) achieves a clock frequency of $1.35$ GHz for configurations up to 8 lanes, with a critical path of approximately 40 FO4 delays. The design is highly parameterized, supporting lane counts of $2$, $4$, $8$, and $16$.

While the area of the functional units scales linearly with the number of lanes, the interconnect structures—particularly the Slide Unit (SLDU) and Mask Unit (MASKU)—exhibit superlinear scaling. To mitigate this, Ara2 restricts slide operations to power-of-two strides, reducing interconnect complexity from $O(L^2)$ to $O(L \log L)$ and enabling feasible scaling to larger lane counts.

In a 16-lane configuration, Ara achieves over $98\%$ FPU utilization on matrix multiplication kernels and a peak energy efficiency of $37.8$ DP-GFLOPS/W. The 64-lane ``AraXL'' variant occupies only $3.8\times$ the area of the 16-lane design, demonstrating near-linear area scaling and superior efficiency compared to traditional SIMD or multi-core scalar architectures.

\subsubsection{Benchmarking Suitability}

Ara is exceptionally well-suited for benchmarking compute-bound machine learning and HPC kernels. For large problem sizes (e.g., $128 \times 128$ matrices), Ara sustains 97--99\% floating-point unit utilization, indicating that memory latency and control overhead are effectively hidden by the microarchitecture.

The bit-accurate and fully RVV-compliant implementation enables precise tuning of kernels written using RVV intrinsics, allowing researchers to analyze lane utilization, register pressure, and instruction scheduling effects. Benchmarking results further show that for smaller problem sizes, multi-core systems with smaller vector units may outperform a single large vector processor, providing valuable insights into architectural trade-offs across scalability regimes.

% ------------------------------------------------------------
% Comparative Analysis
% ------------------------------------------------------------

\subsection{Comparative Analysis and Core Selection Rationale}

The fundamental divergence between Ara and Vicuna represents the architectural spectrum of the RISC-V Vector ISA. Ara is an \textbf{Application-Class} processor designed to maximize the $FLOPS/Watt$ metric, whereas Vicuna is an \textbf{Embedded-Class} coprocessor designed to eliminate timing uncertainty. 

\subsubsection{Architectural Trade-offs}

Table \ref{tab:core_comparison} synthesizes the key technical differences between the two cores. While both comply with the RVV 1.0 standard, they target mutually exclusive operational requirements.

\begin{table}[H]
\centering
\caption{Final Comparative Positioning of RTL Cores}
\label{tab:core_comparison}
\begin{tabular}{|l|p{5cm}|p{5cm}|}
\hline
\textbf{Feature} & \textbf{Vicuna (Architectural Baseline)} & \textbf{Ara (Benchmarking Vehicle)} \\ \hline
ISA Profile & $Zve32x$ (Integer/Fixed-point) & \textbf{Full RVV 1.0 (DP Floating Point)} \\ \hline
Arithmetic Units & Integer ALU, Multiplier & \textbf{VFPU (FMA), VALU, VMUL} \\ \hline
Data Width & $32$-bit & $64$-bit \\ \hline
Primary Limitation & No Floating-Point Support & Superlinear Interconnect Complexity \\ \hline
Thesis Role & Determinism Analysis & \textbf{Performance \& Throughput Validation} \\ \hline
\end{tabular}
\end{table}

\subsubsection{Rationale for Benchmarking on Ara}

While Vicuna offers a highly efficient and predictable environment for quan\-tized neural networks (INT8/INT16), the primary objective of this project is to evaluate the acceleration of high-fidelity ML kernels. Modern convolutional layers ($Conv2D$\allowbreak) and activation functions ($ReLU$\allowbreak) often rely on the dynamic range and precision provided by IEEE-754 float\-ing-point arithmetic to maintain model accuracy during inference.

Because Vicuna implements the $Zve32x$ subset, it lacks the \textbf{"F"} (Single-Precision) and \textbf{"D"} (Double-Precision) vector extensions. Consequently, it is functionally incapable of executing the standard floating-point kernels required for the comparative performance analysis in this study. Furthermore, the specialized memory arbitration in Vicuna, while optimized for Worst-Case Execution Time (WCET) bounds, limits the maximum aggregate memory bandwidth available for the high-intensity data movement required by $MaxPool$\allowbreak\ and strided tensor operations.

\subsubsection{Summary of Methodology Pivot}

As a result of these architectural constraints, the methodology for the remainder of this thesis utilizes the \textbf{Ara} core as the exclusive hardware target for the Performance Validation chapter. Ara's support for \textbf{vector chaining}, its \textbf{lane-based parallelism}, and its ability to handle \textbf{mixed-width floating-point operations} allow for a comprehensive stress-test of the RVV 1.0 specification. By focusing the benchmarking efforts on Ara, this research provides a realistic assessment of how high-performance RISC-V hardware handles the computational density and data-flow bottlenecks of modern deep learning workloads like $Conv2D$, $MaxPool$, and $ReLU$.