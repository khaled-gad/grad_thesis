% !TEX root = ../Thesis.tex
\subsection{Hardware (RTL Cores)}

In the rigorous domain of computer architecture research, particularly within the context of next-generation machine learning (ML) workload acceleration, the simulation environment serves as the foundational bedrock for all performance claims and design space explorations. While high-level functional simulators—such as Spike \cite{spike-simulator} or QEMU \cite{qemu-riscv}—provide a mechanism for validating instruction set architecture (ISA) compliance and functional correctness, they fundamentally lack the temporal fidelity required to model complex microarchitectural phenomena.

\subsubsection{Role of RTL Cores in Architectural Research}

For a graduation thesis focused on the benchmarking of RISC-V vector architectures, relying solely on functional simulation would obscure critical bottlenecks such as pipeline hazards, register file banking conflicts, memory interconnect contention, and the latency costs associated with control flow divergence. Register Transfer Level (RTL) cores, therefore, play an indispensable role. They offer a bit-accurate and cycle-accurate representation of the hardware, synthesized from languages such as System Verilog.

Simulation at this level allows the researcher to observe the precise interaction between the scalar host processor and the vector accelerator, capturing the ``handshake'' overheads that are often idealized in abstract models. Furthermore, RTL simulation is the only methodology capable of generating credible Power, Performance, and Area (PPA) metrics. By simulating the actual hardware description that would eventually be mapped to silicon or Field-Programmable Gate Arrays (FPGAs), researchers can derive energy efficiency numbers (e.g., FLOPS/Watt) and area utilization statistics (e.g., gate counts or Look-Up Table (LUT) usage) that are grounded in physical reality rather than theoretical estimation.

\subsubsection{Importance of Cycle-Accurate Simulation}

The evaluation of vectorized ML kernels requires a simulation environment that can faithfully model the behavior of the RISC-V Vector (RVV) extension. The RVV specification introduces a paradigm of data-level parallelism that is significantly more complex than traditional SIMD (Single Instruction, Multiple Data) approaches found in fixed-width architectures. Features such as Vector Length Agnosticism (VLA), dynamic Element Width (SEW) grouping (LMUL), and masked execution create a vast design space where theoretical efficiency does not always translate to realized performance \cite{riscv-v-spec}.

Cycle-accurate simulation is paramount for evaluating these kernels because it exposes the latency penalties associated with microarchitectural housekeeping. For instance, the ``strip-mining'' loops common in ML kernels require the hardware to dynamically adjust the vector length (\texttt{vsetvli}) and handle potentially misaligned memory accesses. An RTL simulation reveals the setup time of the vector pipeline, the latency of the Vector Load/Store Unit (VLSU) when handling strided accesses (common in tensor operations), and the impact of coherent cache hierarchies on memory bandwidth.

\subsubsection{Evolution of Core Selection: From Vicuna to Ara}

The selection of RTL cores for this research followed an iterative process driven by the increasing complexity of the targeted machine learning (ML) workloads. Initially, \textbf{Vicuna} \cite{vicuna} was selected as the primary benchmarking vehicle due to its focus on the \textbf{Zve32x} integer extension and its suitability for lightweight Field-Programmable Gate Array (FPGA) implementation. However, as the research progressed into high-fidelity ML acceleration—specifically requiring IEEE-754 floating-point support and the full range of \textbf{RVV 1.0} instructions—the limitations of an embedded-class core became apparent.

While Vicuna served as a robust baseline for integer-only quantized kernels, it lacked the Vector Floating-Point Units ($VFPU$) necessary for modern inference and training benchmarks. This necessitated a transition to \textbf{Ara} \cite{ara}, a significantly more powerful and flexible architecture. Unlike the embedded constraints of Vicuna, Ara supports the full $64$-bit floating-point spectrum and provides a much more sophisticated RTL simulation environment, offering higher temporal fidelity and parametric scalability.

Due to these architectural requirements, the methodology for the performance validation phase of this thesis was refined. While both cores are analyzed to represent the diversity of the RISC-V vector ecosystem, the actual benchmarking of complex, compute-intensive kernels—such as $Conv2D$, $MaxPool$, and $ReLU$—is performed exclusively on the \textbf{Ara} core. This approach ensures that the benchmarking suite can evaluate the hardware's ability to handle the high arithmetic intensity and precision demands characteristic of modern neural network layers, which remain outside the functional scope of integer-only embedded cores.

% ------------------------------------------------------------
% Vicuna Vector Processor
% ------------------------------------------------------------

\subsection{Vicuna RISC-V Vector Coprocessor}

\subsubsection{Overview and Design Motivation}

Vicuna is a 32-bit vector coprocessor designed to fill a distinct niche in the RISC-V ecosystem: timing predictability. While most vector processors maximize average-case throughput using caches, out-of-order execution, and banking, these features introduce ``timing anomalies''—situations where a local speedup results in a global slowdown due to pipeline scheduling effects. Vicuna's primary purpose is to serve real-time systems (e.g., automotive Advanced Driver Assistance Systems (ADAS), avionics) where the Worst-Case Execution Time (WCET) must be strictly bounded and analyzable.

Despite its focus on predictability, Vicuna does not sacrifice scalability. It is designed to scale its performance linearly with the number of execution units while maintaining a simple, analyzable timing model. It specifically targets the Zve32x extension—a subset of RVV 1.0 intended for embedded processors that require vectorization for integer workloads (like quantized neural networks) but do not need 64-bit elements or floating-point support.

\subsubsection{Architectural Organization}

Vicuna acts as a coprocessor to a main scalar core. The reference integration uses the Ibex core (a small, efficient 2-stage RISC-V core) or the CV32E40X \cite{cv32e40x}. Communication is handled via the OpenHW Group's CORE-V eXtension Interface (XIF), where the main core fetches instructions and dispatches valid vector instructions to Vicuna.

Vicuna is highly configurable, allowing for independent scaling of the architectural vector length (VLEN) and the physical datapath width (VPIPE\_W). To minimize logic consumption on FPGAs, Vicuna avoids complex sub-word selection multiplexers; instead, it utilizes operand shift registers to feed functional units. Source vector registers are read entirely into these buffers and shifted into the processing pipeline cycle-by-cycle. Furthermore, to eliminate the timing unpredictability of bank conflicts, the Vector Register File (VRF) is implemented as a multi-ported XOR-based RAM rather than a banked architecture. This ensures that register access latency remains constant regardless of the instruction sequence or data pattern.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{figures/Vicuna.jpg}
\caption[Architectural overview of Vicuna and Ibex integration]{Overview of Vicuna's architecture and its integration with the Ibex main core. Both cores share a common data cache with predictable memory arbitration ensuring deterministic timing behavior.}
\label{fig:vicuna_diagram}
\end{figure}

Vicuna executes vector instructions using a dedicated set of functional units: a Vector Load/Store Unit (VLSU) for memory traffic, a Vector ALU (VALU) for integer arithmetic and logic, a Vector Multiplier (VMUL) for integer multiplication, and Vector Slide (VSLD) and Vector Element Units (VELEM) for permutations and reductions. The control logic is designed to be monotonic, ensuring that the progress of an instruction is never hindered by a subsequent instruction—a key requirement for preventing timing anomalies.

\subsubsection{RVV Implementation}

Vicuna implements the RVV 1.0 (Zve32x) extension profile with support for 8-bit, 16-bit, and 32-bit integers. It explicitly excludes floating-point operations and 64-bit element support, which reduces area and complexity while aligning with its embedded target. Vicuna supports configurable vector register lengths (VLEN), typically synthesized with 512-bit sizes in FPGA tests, and handles Element Widths (SEW) of 8, 16, and 32 bits. The execution model ensures that the processing time for a vector of length $N$ is a deterministic function of $N$ and the number of execution units, enabling precise WCET calculation.

\subsubsection{Execution Model}

Vicuna’s execution model is formally grounded in timing monotonicity. The pipeline is modeled across seven abstract stages: \textit{pre}, \textit{IF}, \textit{ID+EX}, \textit{VQ} (Vector Queue), \textit{VEU} (Vector Execution Units), \textit{postS}, and \textit{postV}. This structure ensures that any pipeline stage can only be stalled by a subsequent stage in the program order, effectively preventing timing anomalies (where a local speedup, such as a cache hit, results in a global execution delay). This monotonic behavior is a sufficient condition for compositional timing analysis, enabling the derivation of a tight Worst-Case Execution Time (WCET) that is mathematically guaranteed to be the maximum possible latency.

Parallelism in Vicuna is achieved through simultaneous and successive processing. Multiple elements are processed in a single cycle if the data path width allows (e.g., processing four 8-bit elements on a 32-bit datapath). For vectors longer than the datapath width, the unit processes chunks sequentially over multiple cycles, amortizing the instruction fetch cost through temporal vectorization.

\subsubsection{Memory Subsystem}

Vicuna supports the standard RVV memory access patterns: unit-stride, strided, and indexed (scatter/gather). Vicuna maintains memory predictability through a strict-ordering memory arbiter governing a shared 2-way Least Recently Used (LRU) data cache. To prevent the scalar core from interfering with vector timing, the arbiter always grants precedence to vector accesses. Crucially, it prevents \textit{amplification timing anomalies} by delaying any scalar access following a cache miss until all pending vector load/store operations are completed. This mechanism ensures that the memory interface—typically a source of non-determinism—behaves in a strictly predictable manner, allowing the scalar core to stall only for a bounded, deterministic number of cycles during vector memory activity.

\subsubsection{RTL Implementation}

Vicuna is implemented in SystemVerilog with a focus on FPGA deployment, particularly the Xilinx 7 Series. The design is compact, with resource utilization (LUTs and Flip-Flops) comparable to other soft-core vector processors like VESPA or VEGAS, yet offering higher performance due to its pipelining and RVV compliance. On a Xilinx 7 Series FPGA, Vicuna achieves a clock frequency of 80 MHz with a peak throughput of 10.24 billion operations per second for 8-bit operations (128 MACs/cycle).

The verification strategy for Vicuna focuses on proving timing constancy using Verilator, Questasim, and xsim. The primary verification metric is that benchmarks (e.g., matmul) must execute in the exact same number of cycles for every run, regardless of input data values. This confirms the absence of timing anomalies through repeated validation using a suite of benchmarks (AXPY, CONV2D, GEMM).

\subsubsection{Benchmarking Suitability}

Vicuna represents the \textit{predictable-efficiency} design point in the benchmarking suite. While timing-predictable multi-core systems (e.g., T-CREST) typically scale performance logarithmically due to interconnect contention, Vicuna’s performance scales linearly with its datapath width. In compute-bound kernels such as GEMM, Vicuna achieves a multiplier utilization exceeding 90\% (reaching up to 99.5\% in smaller configurations), significantly outperforming other soft-vector processors like VEGAS (49\%). This efficiency proves that the removal of non-deterministic optimizations (e.g., out-of-order write-back, banked VRFs) does not result in a significant performance penalty for data-parallel tasks, making it a robust baseline for 8-bit quantized edge AI applications.

% ------------------------------------------------------------
% Ara Vector Processor
% ------------------------------------------------------------

\subsection{Ara Vector Processor}

\subsubsection{Overview and Design Motivation}

Ara \cite{ara} is a 64-bit vector processor designed for high-throughput, energy-efficient execution of data-parallel workloads. Unlike Vicuna’s focus on timing predictability, Ara is optimized for maximal floating-point utilization, making it suitable for High-Performance Computing (HPC) and Machine Learning (ML) applications. It implements the full RVV 1.0 specification, supporting a wide range of data types from 64-bit double-precision floating-point values down to 8-bit integers.

Ara operates as a coprocessor tightly coupled with a scalar host core, specifically the \textbf{CVA6} (formerly Ariane) \cite{cva6}. Its primary architectural goal is to amortize the instruction fetch and decode costs of the scalar core across long vector sequences, achieving a high ratio of FLOPS per Watt. The design explicitly draws inspiration from classical vector supercomputers such as the Cray-1, positioning Ara as a leading open-source RISC-V vector architecture.

The version of Ara utilized in this research represents the second generation of the architecture (often referred to in literature as \textbf{Ara2}). This iteration was specifically re-engineered for strict compliance with the ratified \textbf{RISC-V Vector Extension version 1.0}, introducing substantial microarchitectural changes to support dynamic vector length configuration, masking semantics, and mixed element widths.

\subsubsection{Architectural Organization}

The Ara system operates as a coherent vector coprocessor. CVA6 manages the control plane, including instruction fetch and exception handling. Vector instructions are dispatched to Ara only after they are committed in the scalar pipeline, ensuring non-speculative execution.

Ara’s microarchitecture is composed of $N$ identical vector lanes (typically 2, 4, 8, or 16). Each lane contains a slice of the Vector Register File (VRF) and functional units (VALU and VFPU). To provide high register bandwidth, Ara implements a \emph{barber-pole} banking scheme. This layout ensures that vector elements are distributed such that most operations find their operands locally within the lane, minimizing cross-lane data movement.



\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{figures/ara.jpg}
\caption[Top-level block diagram of the Ara system]{Top-level block diagram of the Ara system showing the vector coprocessor, lane-based organization, and integration with the CVA6 scalar host.\cite{ara}}
\label{fig:ara_diagram}
\end{figure}

\subsubsection{Vector Execution Model}

Ara adheres to the \textbf{Vector Length Agnostic (VLA)} model. While the hardware vector length (VLEN) is fixed, the \texttt{vsetvli} instruction allows software to configure the application vector length (AVL) dynamically. If the AVL exceeds the hardware capacity, Ara transparently strip-mines the operation into temporal chunks.

For reduction operations, Ara employs a three-step algorithm: local partial reductions within lanes, cross-lane shuffling, and a final scalar write-back. This decoupled model allows arithmetic pipelines to remain highly utilized even during irregular data access patterns.

\subsubsection{Memory Subsystem and Coherence}

The Vector Load/Store Unit (VLSU) interfaces Ara with the high-bandwidth Advanced Extensible Interface (AXI) memory system, supporting unit-stride, strided, and indexed (scatter/gather) accesses. A critical feature of this implementation is the robust hardware coherence mechanism: the CVA6 data cache operates in write-through mode, ensuring scalar stores are visible to Ara, while vector stores generate invalidation signals to the CVA6 cache to maintain a consistent memory view.

\subsubsection{RTL Implementation and Scalability}

Implemented in GlobalFoundries 22FDX technology, Ara achieves a clock frequency of $1.35$~GHz. The design is highly parameterized; while functional units scale linearly with lane counts, the interconnect structures (Mask and Permutation units) scale superlinearly. By restricting certain operations to power-of-two strides, Ara reduces interconnect complexity from $O(L^2)$ to $O(L \log L)$, enabling feasible scaling up to 16 lanes and beyond.

\subsubsection{Benchmarking Suitability}

Ara is exceptionally well-suited for benchmarking compute-bound ML kernels. For large problem sizes, Ara sustains 97--99\% floating-point unit utilization, indicating that memory latency and control overhead are effectively hidden. This makes it an ideal platform for evaluating the library of kernels developed in this thesis, providing clear insights into lane utilization and arithmetic intensity.

% ------------------------------------------------------------
% Comparative Analysis
% ------------------------------------------------------------

\subsection{Comparative Analysis and Core Selection Rationale}

The fundamental divergence between Ara and Vicuna represents the architectural spectrum of the RISC-V Vector ISA. Ara is an \textbf{Application-Class} processor designed to maximize the $FLOPS/Watt$ metric, whereas Vicuna is an \textbf{Embedded-Class} coprocessor designed to eliminate timing uncertainty. 

\subsubsection{Architectural Trade-offs}

Table \ref{tab:core_comparison} synthesizes the key technical differences between the two cores. While both comply with the RVV 1.0 standard, they target mutually exclusive operational requirements.

\begin{table}[H]
\centering
\caption{Final Comparative Positioning of RTL Cores}
\label{tab:core_comparison}
\begin{tabular}{|l|p{5cm}|p{5cm}|}
\hline
\textbf{Feature} & \textbf{Vicuna (Architectural Baseline)} & \textbf{Ara (Benchmarking Vehicle)} \\ \hline
ISA Profile & $Zve32x$ (Integer/Fixed-point) & \textbf{Full RVV 1.0 (Double Precision Floating Point)} \\ \hline
Arithmetic Units & Integer ALU, Multiplier & \textbf{VFPU (FMA), VALU, VMUL} \\ \hline
Data Width & $32$-bit & $64$-bit \\ \hline
Primary Limitation & No Floating-Point Support & Superlinear Interconnect Complexity \\ \hline
Thesis Role & Determinism Analysis & \textbf{Performance \& Throughput Validation} \\ \hline
\end{tabular}
\end{table}

\subsubsection{Rationale for Benchmarking on Ara}

While Vicuna offers a highly efficient and predictable environment for quan\-tized neural networks (INT8/INT16), the primary objective of this project is to evaluate the acceleration of high-fidelity ML kernels. Modern convolutional layers ($Conv2D$\allowbreak) and activation functions ($ReLU$\allowbreak) often rely on the dynamic range and precision provided by IEEE-754 float\-ing-point arithmetic to maintain model accuracy during inference.

Because Vicuna implements the $Zve32x$ subset, it lacks the \textbf{"F"} (Single-Precision) and \textbf{"D"} (Double-Precision) vector extensions. Consequently, it is functionally incapable of executing the standard floating-point kernels required for the comparative performance analysis in this study. Furthermore, the specialized memory arbitration in Vicuna, while optimized for Worst-Case Execution Time (WCET) bounds, limits the maximum aggregate memory bandwidth available for the high-intensity data movement required by $MaxPool$\allowbreak\ and strided tensor operations.

\subsubsection{Summary of Methodology Pivot}

As a result of these architectural constraints, the methodology for the remainder of this thesis utilizes the \textbf{Ara} core as the exclusive hardware target for the Performance Validation chapter. Ara's support for \textbf{vector chaining}, its \textbf{lane-based parallelism}, and its ability to handle \textbf{mixed-width floating-point operations} allow for a comprehensive stress-test of the RVV 1.0 specification. By focusing the benchmarking efforts on Ara, this research provides a realistic assessment of how high-performance RISC-V hardware handles the computational density and data-flow bottlenecks of modern deep learning workloads like $Conv2D$, $MaxPool$, and $ReLU$.