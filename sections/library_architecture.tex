% !TEX root = ../Thesis.tex
\section{Open Source Library Architecture}

This section describes the architecture of the open-source RaiVeX library, developed to provide accessible interfaces to RISC-V Vector Extension (RVV) accelerated neural network kernels. The library bridges the gap between low-level RVV intrinsics and high-level programming languages, enabling researchers and developers to leverage hardware acceleration without requiring expertise in assembly programming.

\subsection{Repository Structure}

The RaiVeX repository is organized as follows:

\begin{verbatim}
RaiVeX/
+-- kernels/
|   +-- batch_norm/
|   +-- bias_add/
|   +-- conv/
|   +-- conv_transpose/
|   +-- dense/
|   +-- gather/
|   +-- gather_elements/
|   +-- leaky_relu/
|   +-- matmul/
|   +-- maxpool/
|   +-- nms/
|   +-- relu/
|   +-- scatter_elements/
|   +-- softmax/
|   +-- tensor_add/
+-- lib/
|   +-- rvv.h
|   +-- rvv_math.h
|   +-- ...
+-- libso/
+-- models/
|   +-- lenet-5/
|   +-- tiny-yolov2/
+-- pyv/
|   +-- kernels.py
|   +-- __init__.py
|   +-- ...
+-- scripts/
+-- README.md
+-- requirements.txt
\end{verbatim}

\subsection{Explanation of Repository Contents}

The repository is structured to support the development, testing, and deployment of RVV-accelerated kernels. The \texttt{kernels/} directory contains individual kernel implementations, each organized in its own subdirectory with source code, test scripts, and build files. The \texttt{lib/} directory provides low-level RVV vector APIs implemented as C++ headers, wrapping RVV instructions into reusable building blocks such as vector loads/stores, mask operations, reductions, and multiply-accumulate operations. The \texttt{libso/} directory contains shared object files for building shared libraries. The \texttt{models/} directory includes complete neural network implementations using the kernels, such as LeNet-5 and Tiny-YOLOv2. The \texttt{pyv/} directory provides Python bindings for the kernels, enabling high-level usage. The \texttt{scripts/} directory contains utility scripts for testing and benchmarking.

The library implements kernels categorized according to the six computational patterns introduced in Section 3.1 of the Methodology chapter:

\begin{enumerate}
    \item \textbf{Compute-intensive FMA Operations}: Matrix multiplication (\texttt{kernels/matmul/}) and dense (fully connected layer, \texttt{kernels/dense/}).
    \item \textbf{Sliding-window kernels}: Convolution (\texttt{kernels/conv/}), transposed convolution \newline(\texttt{kernels/conv\_transpose/}), and max pooling (\texttt{kernels/maxpool/}).
    \item \textbf{Pointwise activations and elementwise arithmetic}: ReLU (\texttt{kernels/relu/}), Leaky ReLU (\texttt{kernels/leaky\_relu/}), tensor addition (\texttt{kernels/tensor\_add/}), and bias addition (\texttt{kernels/bias\_add/}).
    \item \textbf{Tensor indexing and data movement}: Gather (\texttt{kernels/gather/}), gather elements (\texttt{kernels/gather\_elements/}), and scatter elements (\texttt{kernels/scatter\_elements/}).
    \item \textbf{Statistical and normalization layers}: Batch normalization (\texttt{kernels/batch\_norm/}).
    \item \textbf{Postprocessing (NMS)}: Non-maximum suppression (\texttt{kernels/nms/}).
\end{enumerate}

\subsection{Wrappers Overview}

The library employs two types of wrappers to abstract RVV intrinsics for different levels of usage.

\subsubsection{Intrinsic Wrappers}

Intrinsic wrappers are implemented in C/C++ functions that abstract RVV intrinsics to improve readability and maintainability. These wrappers are defined in the \texttt{lib/} directory, such as \texttt{lib/rvv.h} and \texttt{lib/rvv\_math.h}. For example, a wrapper for vector addition might be implemented as:

\begin{lstlisting}[language=C++]
inline vfloat32m1_t vadd(vfloat32m1_t a, vfloat32m1_t b, size_t vl) {
    return __riscv_vfadd_vv_f32m1(a, b, vl);
}
\end{lstlisting}

This abstraction allows kernel implementations in \texttt{kernels/} to use high-level function calls instead of direct intrinsics, enhancing code portability and maintainability.

\subsubsection{Python Wrappers}

Python bindings are provided in the \texttt{pyv/} directory, enabling higher-level and real-world usage of the kernels. The bindings use ctypes to interface with compiled C shared libraries, allowing seamless integration with Python machine learning workflows. For instance, the ReLU kernel can be invoked from Python as shown in \texttt{models/lenet-5/py/main.py}:

\begin{lstlisting}[language=Python]
from pyv.kernels import relu
output = relu(input_tensor, variant="M8")
\end{lstlisting}

This approach provides NumPy compatibility, automatic memory management, and variant selection for performance tuning.

\subsection{Results Verification}

To ensure correctness of the RVV implementations, the library includes comprehensive verification frameworks:

\subsubsection{Correctness Testing}

Each kernel implementation is verified against reference implementations using:
\begin{itemize}
    \item NumPy-based scalar reference implementations
    \item PyTorch/TensorFlow operations for complex kernels
    \item Statistical comparison metrics (mean absolute error, relative error)
    \item Edge case testing (zero inputs, overflow conditions, etc.)
\end{itemize}

\subsubsection{Automated Testing}

The verification suite includes:
\begin{itemize}
    \item Unit tests for individual kernel functions
    \item Integration tests for end-to-end neural network layers
    \item Cross-validation between different LMUL variants
    \item Regression tests to prevent performance regressions
\end{itemize}

\subsection{Performance Results}

The library provides extensive performance benchmarking capabilities to quantify the benefits of RVV acceleration:

\subsubsection{Benchmarking Framework}

The performance analysis includes:
\begin{itemize}
    \item Microbenchmarks for individual kernel operations
    \item End-to-end model performance measurements
    \item Memory bandwidth utilization analysis
    \item Scalability testing across different tensor sizes
\end{itemize}

\subsubsection{Performance Metrics}

Key performance indicators tracked:
\begin{itemize}
    \item Operations per second (OPS)
    \item Memory throughput (GB/s)
    \item Energy efficiency (OPS/W)
    \item Speedup ratios compared to scalar implementations
\end{itemize}

\subsection{Wrapper Interfaces}

The Python wrappers provide consistent, NumPy-compatible interfaces for all kernels. Each wrapper handles:

\begin{itemize}
    \item Input tensor validation and shape checking
    \item Automatic memory allocation for output tensors
    \item Variant selection based on input characteristics
    \item Error handling and informative error messages
\end{itemize}

\begin{table}[htbp]
\centering
\caption{Kernel Variants and Implementation Availability}
\label{tab:kernel_variants}
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
\textbf{Kernel} & \textbf{Scalar} & \textbf{M1} & \textbf{M2} & \textbf{M4} & \textbf{M8} & \textbf{Tiled} \\
\hline
ReLU & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & -- \\
\hline
Leaky ReLU & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark \\
\hline
MatMul & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & -- \\
\hline
Tensor Add & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & -- \\
\hline
Batch Norm & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark \\
\hline
Bias Add & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & -- \\
\hline
Conv2D & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & 3x3 Specialized \\
\hline
Conv2D Transpose & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & 3x3 Specialized \\
\hline
Dense (FC) & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & -- \\
\hline
MaxPool & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark \\
\hline
Softmax & \checkmark & -- & -- & -- & -- & -- \\
\hline
\end{tabular}
\end{table}
\newpage
\subsubsection{Example Function Signature}

As an example, the ReLU activation function signature in \texttt{pyv/kernels.py} is:

\begin{lstlisting}[language=Python]
def relu(x: np.ndarray, variant: str = "M8") -> np.ndarray:
    """
    Apply ReLU activation element-wise to input tensor.
    
    Args:
        x: Input tensor of any shape, dtype float32
        variant: Implementation variant ("scalar", "M1", "M2", "M4", "M8")
    
    Returns:
        Output tensor with same shape as input, ReLU applied element-wise
    """
\end{lstlisting}

This signature demonstrates the consistent interface design across all kernel wrappers, with optional variant selection for performance tuning.
